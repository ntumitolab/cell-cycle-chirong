{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tifffile\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'folder of the analyses of mitochondria'\n",
    "file = folder + 'Analyze_Particle/summary/'\n",
    "\n",
    "filelist = []\n",
    "for filename in os.listdir(file):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filelist.append(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath = []\n",
    "for i in range(len(RFP)):\n",
    "    #temp = filelist[i].split('.')[0]\n",
    "    #temp = temp.replace('_','/')\n",
    "    imagepath.append('path to the images containing nucleus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleus_area = []\n",
    "for j in range(len(imagepath)):\n",
    "    img = tifffile.imread(imagepath[j])\n",
    "    imgb = (img[0] > (img[0].mean()+0.5*img[0].std())).astype(np.uint8)*255\n",
    "    count = np.count_nonzero(imgb)\n",
    "    nucleus_area.append(0.26 * 0.26 *count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for nolabel data\n",
    "file_name_list = filelist\n",
    "Count = []\n",
    "nCount = []\n",
    "TotalArea = []\n",
    "AverageArea = []\n",
    "Perimeter = []\n",
    "FormFactor = []\n",
    "\n",
    "\n",
    "for j in range(len(file_name_list)):\n",
    "    df = pd.read_csv(folder + f'Analyze_Particle/summary/{file_name_list[j]}', index_col=0)\n",
    "    Count.append(float(df['Count']))\n",
    "    TotalArea.append(float(df['Total Area']))\n",
    "    AverageArea.append(float(df['Average Size']))\n",
    "    Perimeter.append(float(df['Perim.']))\n",
    "    FormFactor.append(np.reciprocal(float(df['Circ.'])))\n",
    "    nCount.append(float(df['Count'])/float(df['Total Area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p_results = folder + 'Analyze_Particle/results/'\n",
    "        \n",
    "filelist = []\n",
    "for filename in os.listdir(file_p_results):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filelist.append(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_list = filelist\n",
    "AspectRatio = []\n",
    "MaxArea = []\n",
    "\n",
    "for j in range(len(file_name_list)):\n",
    "    df = pd.read_csv(folder + f'Analyze_Particle/results/{file_name_list[j]}', index_col=0)\n",
    "    AspectRatio.append(df['AR'].mean())\n",
    "    MaxArea.append(df.loc[df['Area'].idxmax()]['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_area = np.array(MaxArea)/np.array(TotalArea)\n",
    "MaxTotal = temp_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nonlabel data\n",
    "\n",
    "file_s_summary = folder + 'Analyze_Skeleton/summary/'   \n",
    "\n",
    "filelist = []\n",
    "for filename in os.listdir(file_s_summary):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filelist.append(filename) \n",
    "\n",
    "\n",
    "file_name_list = filelist\n",
    "\n",
    "TotalBranches = []\n",
    "AvgBranches = []\n",
    "ABL = []\n",
    "BLpM = []\n",
    "TotalDeg1 = []\n",
    "TotalDeg2 = []\n",
    "TotalDeg3 = []\n",
    "AvgDeg1 = []\n",
    "AvgDeg2 = []\n",
    "AvgDeg3 = []\n",
    "AvgDeg = []\n",
    "\n",
    "\n",
    "\n",
    "for j in range(len(file_name_list[i])):\n",
    "    df = pd.read_csv(folder + f'Analyze_Skeleton/summary/{file_name_list[j]}', index_col=0)\n",
    "    # Calculate deg 2\n",
    "    fake_deg2 = np.zeros(df[df.columns[0]].count())\n",
    "    deg2 = np.zeros(df[df.columns[0]].count())\n",
    "    real_ABL = np.sum(df['# Branches'] * df['Average Branch Length']) / np.sum(df['# Branches'])\n",
    "    for k in range(len(deg2)):\n",
    "        fake_deg2[k] = (df['# Branches'][k+1] * df['Average Branch Length'][k+1]) / real_ABL\n",
    "        dif = round(fake_deg2[k] - (df['# End-point voxels'][k+1] + df['# Junctions'][k+1])) # dif = #2 - (#1 + #3), 0)\n",
    "        if dif <= 0:\n",
    "            deg2[k] = 0\n",
    "        elif dif > 0 :\n",
    "            deg2[k] = dif\n",
    "    df['fake_Deg2'] = fake_deg2\n",
    "    df['Deg2'] = deg2\n",
    "        \n",
    "    TotalBranches.append(df['# Branches'].sum())\n",
    "    AvgBranches.append(df['# Branches'].mean())\n",
    "    ABL.append(df['Average Branch Length'].mean())\n",
    "    BLpM.append((df['# Branches'] * df['Average Branch Length']).mean())\n",
    "    TotalDeg1.append(df['# End-point voxels'].sum())\n",
    "    TotalDeg2.append(df['Deg2'].sum())\n",
    "    TotalDeg3.append(df['# Junctions'].sum())\n",
    "    AvgDeg1.append(df['# End-point voxels'].mean())\n",
    "    AvgDeg2.append(df['Deg2'].mean())\n",
    "    AvgDeg3.append(df['# Junctions'].mean())\n",
    "    avgdeg = (df['# End-point voxels'].sum() + 2*df['Deg2'].sum() + 3*df['# Junctions'].sum()) / (df['# End-point voxels'].sum() + df['Deg2'].sum() + df['# Junctions'].sum())\n",
    "    AvgDeg.append(avgdeg)\n",
    "        \n",
    "TotalDeg1 = np.array(TotalDeg1)\n",
    "TotalDeg2 = np.array(TotalDeg2)\n",
    "TotalDeg3 = np.array(TotalDeg3)\n",
    "\n",
    "\n",
    "# Deg1_to_Deg3\n",
    "temp_data = TotalDeg1/TotalDeg3\n",
    "Deg1_to_Deg3 = temp_data\n",
    "\n",
    "# nDeg1\n",
    "temp_data = TotalDeg1/TotalArea\n",
    "nDeg1 = temp_data\n",
    "\n",
    "#nDeg2\n",
    "temp_data = TotalDeg2/TotalArea\n",
    "nDeg2 = temp_data\n",
    "\n",
    "#nDeg3\n",
    "temp_data = TotalDeg3/TotalArea\n",
    "nDeg3 = temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'normal_count':nCount,\n",
    "        'Average Branches':AvgBranches,\n",
    "        'Average Degree':AvgDeg,\n",
    "        'AVerage Area':AverageArea,\n",
    "        'Perimeter':Perimeter,\n",
    "        'nuclei_area':nucleus_area,\n",
    "       }\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data.to_csv(folder + 'SVMdata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('path to the trained SVM model')\n",
    "ypred=clf.predict(df_data.iloc[:,0:6])\n",
    "print(ypred)\n",
    "\n",
    "# 1:G1 0:S/G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'file':filelist,'prediction':ypred})\n",
    "df2.to_csv(folder+'SVMprediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
